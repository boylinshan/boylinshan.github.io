---
layout: post
title: 'Mesos学习笔记'
category: Notes
---

## Mesos学习笔记

[Mesos: A Platform for Fine-Grained Resource Sharing in the Data Center](http://mesos.berkeley.edu/mesos_tech_report.pdf)
#### 什么是Mesos

*What is Mesos? A distributed systems kernel*, 在Apache Mesos的官网上用这么一句话介绍了Mesos。我们都知道Operating System是用来管理计算机上的资源的，并向上层应用提供使用这些资源的接口，Mesos大致上也是完成了类似的功能。区别于传统OS，Mesos是应用于分布式的场景，即可以理解为Mesos整合了一个集群而非单个结点的资源，并对外提供统一的接口使用。

#### 为什么使用Mesos

众所周知，近年来集群(Clusters of server)已经成为了主流的计算机资源平台。越来越多的分布式应用也开始部署在集群上。通常而言，一个cluster或一个VM往往只供应与一种framework，例如MapReduce，Dryad，MPI等等。这也是因为各个Framework都是独立开发的，谁也不知道放在一起运行资源分配以及运行上会不会有什么冲突，而Mesos就是做这个事情的。Mesos协调了不同framework之间资源的分配并确保他们可以互不干扰的运行。Mesos是在一种更精细的层级上完成这个工作的。通俗的理解，就是一个cluster或一个VM上可以运行不同framework的任务了，也即是提高了资源利用率。

#### Mesos总体架构

![RPyC](/img/architecture3.jpg)

为了能够应对多种不同的framework的运行，Mesos将以往的集群管理系统的功能分为两部分，资源管理和任务调度。Mesos专注于资源管理，而将任务调度的工作交给了每一个framework自己去完成，即Mesos中的master收集所有slave上可用的资源，并按照资源分配策略将信息提供给注册的frameworks，framework自己决定要使用哪些资源运行哪些任务。Master结点上的资源分配模块以插件的机制运行，这使的使用者可以自定义资源分配策略。另外Master结点使用ZooKeeper保障容错。Framework也由两部分组成，scheduler和executor。scheduler注册到master结点上，等待其提供资源，而executor运行在slave结点上等待执行具体的任务。

![RPyC](/img/architecture-example.jpg)

上图表明了一次资源分配的流程。
1. Slave 1向Master提供自己空闲的资源 (s1, 4cpu, 4gb)，然后Master上的Allocation policy模块开始运行计算出应向Framework 1提供多少资源。
2. Master向Framework 1发送资源的描述(s1, 4cpu, 4gb)。
3. Framework 1的scheduler回复Master自己使用的资源以及运行在上面的任务。(task1, s1, 2cpu, 1gb), (task2, s1, 1cpu, 2gb)。为了某些需求如数据本地化，Framework可以拒绝使用此次资源。
4. Master将收到的任务信息发送到相应的slave上，并通知其开始执行任务。

这一资源分配流程会在有新的可用资源时被触发。

#### Master资源管理

Mesos假设它所在的环境中，每一个task的运行时间都是相对较短的。所以Mesos仅在task完成时重新分配资源。Mesos目前提供两种资源分配的方式*fair sharing* 和*strict priorities*。当然对于那些运行时间较长的task，Mesos也具有revocation机制。具体的Revocation策略与Allocation模块相关，Mesos本身的实现方式为，对于长时间运行的task，Master将会通知对应的executor kill掉它。当executor没有回应时，Master简单暴力的kill掉整个executor。

为了减轻杀死task对framework的影响，Mesos可以对于每个framework保障一个最低限度的资源分配，当framework占有的资源处于最低限度下时，任何任务都不会被kill掉。Allocation模块保障所有运行framework都能同时具有最低限度的资源分配。

Mesos使用操作系统相关的机制来确保资源的隔离性。目前实现了Linux Contaniner和Solaris projects的支持。因为资源隔离机制也是以插件的形式运行的，所以使用者可以扩展自己的需求。

此外，为了保证提供资源时的健壮性以及可扩展性，Mesos实现了三种机制。
1. Filter: 因为framework可能始终拒绝某些资源，为了减少拒绝时的开销。Mesos提供了filter，framework可以定义自己的filter，Meos仅提供满足filter的资源。默认的每次拒绝资源后，Mesos添加5s的filter。目前Mesos支持两种filter方式。
	- *only offer node from list L*
	- *only offer nodes with at least R resources free*
2. Count Resources: Mesos记录提供给某个framework的资源总数以供Allocation模块使用，这也鼓励framework更快的回应master消息。
3. Rescind Offer: 当framework不回应resources offer时，Mesos rescind这一次recources offer，并将其提供给其他framework。

#### Mesos容错机制

对于Master结点的容错，Mesos使用了两种机制。
1. Soft state: Master的内部状态可以根据slaves以及framework schuduler周期性发送的消息重构出来。因此Master failure时并不会造成状态的丢失。
2. Hot-Standby: Master以replica set的形式运行，当主master出问题时，Mesos使用ZooKeeper选取出新的主master，因为master是soft state的，所有新的主master可以很快恢复到原有的状态。

对于task以及executor的错误，Mesos将信息转发到相应的framework，由framework提供具体的容错机制。
对于scheduler的容错，Mesos允许framwork注册多个scheduler到master上，但是多个scheduler状态间的同步，需要framework自己实现。
简而言之，Mesos本身仅对Master结点提供了具体的容错机制，而对于task，executor以及scheduler，只是提供了接口。
