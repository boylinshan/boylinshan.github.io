---
layout: post
title: 'Kafka学习笔记'
category: Notes
---

## Kafka学习笔记


### 消息系统

消息系统是将应用中处理数据传递的部分独立处理，与具体的处理流程解耦。一个应用往往是由多个不用的功能部分组成，这些功能间通过数据相互交流协作，最终呈现出一个完整的应用。当应用分布在不同的机器上时，消息的传递往往是一个很复杂的过程，而消息系统则将应用的开发从繁琐的消息管理中解放出来，而且目前有很多成熟，开源的消息系统可以使用。


### 流处理平台

Kafka是由LinkedIn开源的一个分布式的流处理平台，而流处理平台有以下三点特性：
1. 支持数据流的发布与订阅，如同消息队列一样使用。
2. 支持具有容错性的数据流存储，提供relica机制来容错。
3. 支持实时数据处理。

### Kafka简介

#### 应用场景

Kafka擅长于工作在以下两个领域。
1. 在系统组件间构建实时数据流管道。
2. 构建实时数据流处理应用，也就是说Kafka不仅仅可以很好的传递数据流，还可以在传递数据流的过程中，对数据流进行加工。

#### 基本概念

- Kafka以集群的形式运行。
- Kafka以topic的形式对数据进行分类。
- Kafka将原始数据流组织成record形式，record具有key, value以及tmestamp。
- Kafka对外提供四种APIs，即对Kafka来说，外部应用分为四类。
	- Producer: 数据的提供者，发布数据到topics。
	- Consumer: 数据的使用者，订阅不同topics中的数据。
	- Stream: 数据处理应用，读取数据处理后再写入到Kafka。
	- Connector: 数据持久化部分，可以为Kafka提供已经被持久化的数据(离线处理)或将数据持久化。
- 在Kafka中，数据的通信使用TCP协议。

![RPyC](/img/kafka-apis.png)

#### 术语

Kafka中有以下几个术语：
- Broker：组成Kafka集群的服务器。
- Topic：消息的类别，每个消息都有一个类别，如同图书馆中书籍的分类标签一样。
- Partition：每个topic都由一个或多个partition组成，partition物理上就是一个存储数据的文件夹。
- Producer：消息的生成者，负责发送消息到Kafka Broker。
- Consumer：消息的使用者，从Kafka中读取消息。每一个Consumer都有一个group，同一个topic中的一条消息只能被一个group中的一个cosumer使用。所有consumer属于同一group时，即为单播，所有consumer属于不同组时，即为广播。

#### 基本架构

![RPyC](/img/KafkaArchitecture.png)

#### Topics and Logs

Topic是Kafka中对record的抽象概念，Producer在发布records时，每一个record都有所属的topic。topic也是consumer获取record的途径。consumer会从所订阅的topic中获取数据。Topic又由partition组成，topic将数据分散的存储到所有的partitions中，partition机制为数据的并行处理提供了便利性。
![RPyC](/img/log_anatomy.png)
在每一个partition中record都是有序的，不可变更的数据列。每一个record都有一个id标识着自己在partition中的偏移量。

Kafka中records并不会因为Consumer读取而删除，而是根据配置文件中配置的时间或者数据集大小管理。也就是说一个record可以被多次消费。而每一个Consumer也会维护一个offset来标识当前读取的位置。通常来说，Consumer成功消费了数据后，将线性的增加offset，但Consumer也可以任意的更改offset，例如通过减少offset可以读取已经消费过的数据。

Kafka对于record的这种管理方式，为不同的Consumer间提供了隔离性，一个Consumer读取数据并不会影响到其他的Consumer。

#### 分布式

Kafka中topic由多个partitions组成，每个partition可以分布在不同的server上。每个partition都可以以replica set的形式提供服务。即由一组server组成一个partition。这一组server中，有一个leader负责数据的读写操作，而其他的server均作为follwer，来备份leader上的数据操作。当leader crash时，其余的follwers会选取出一个新的leader来，这一系列的过程都借助于kafka系统中的ZooKeeper完成。通常来说，系统中的server往往服务于多个partition，这样有利于数据的备份。

#### Producer

Producer发布数据到特定的topics，而且在Kafka中，由Producer决定要将数据存储到哪一个partition上。虽然Kafka使用partition机制提供了负载均衡和扩张的功能，但是此机制是否work还是取决于Producer分发数据的方式。最简单的方法是round-robin。

#### Consumer

每一个Consumer都有其对应的group，同一个topic中的record只会被同一个group中的一个Consumer使用，实际上这也是一种负载均衡和扩展的机制。一个Group中的Consumer可以是不同的进程，也可以是不同的机器。
- 当所有的Consumer处于一个Group中时，即实现了records处理时的负载均衡。
- 当所有的Consumer处于不同Group中时，即实现了records的广播。

![RPyC](/img/consumer-groups.png)
上图是Kafka分发Records到Consumers的一个示例，records以partition为单位分发到Consumers上，即一个Group中的Consumer排它的负责几个partitions。Consumers间的负载均衡由一个Coordinator负载，当加入或者删除Consumer时，负载均衡启动。Coordinator从ZooKeeper获取信息。可以看出，由于Kafka仅保证partition上数据的顺序性，所以对于一个Topic而言，数据的处理可能与发布的顺序不一致。






